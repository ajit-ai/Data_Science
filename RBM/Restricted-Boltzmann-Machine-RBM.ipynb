{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbbc4453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Reconstruction Error: 0.4940\n",
      "Epoch 10, Reconstruction Error: 0.5020\n",
      "Epoch 20, Reconstruction Error: 0.4890\n",
      "Epoch 30, Reconstruction Error: 0.4600\n",
      "Epoch 40, Reconstruction Error: 0.4750\n",
      "Epoch 50, Reconstruction Error: 0.4310\n",
      "Epoch 60, Reconstruction Error: 0.4270\n",
      "Epoch 70, Reconstruction Error: 0.4150\n",
      "Epoch 80, Reconstruction Error: 0.3760\n",
      "Epoch 90, Reconstruction Error: 0.4080\n",
      "Original: [[0. 1. 1. 1. 0. 0. 0. 1. 1. 1.]]\n",
      "Reconstructed: [[0. 1. 0. 0. 0. 0. 0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RBM:\n",
    "    def __init__(self, n_visible, n_hidden, learning_rate=0.01, k=1):\n",
    "        \"\"\"\n",
    "        Initialize a Restricted Boltzmann Machine.\n",
    "        \n",
    "        Parameters:\n",
    "        - n_visible: Number of visible units\n",
    "        - n_hidden: Number of hidden units\n",
    "        - learning_rate: Learning rate for weight updates\n",
    "        - k: Number of Gibbs sampling steps for Contrastive Divergence (CD-k)\n",
    "        \"\"\"\n",
    "        self.n_visible = n_visible\n",
    "        self.n_hidden = n_hidden\n",
    "        self.learning_rate = learning_rate\n",
    "        self.k = k\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.W = np.random.normal(0, 0.01, (n_visible, n_hidden))  # Weight matrix\n",
    "        self.b = np.zeros(n_visible)  # Visible biases\n",
    "        self.c = np.zeros(n_hidden)   # Hidden biases\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"Compute sigmoid activation.\"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sample_hidden(self, v):\n",
    "        \"\"\"\n",
    "        Sample hidden units given visible units.\n",
    "        Returns: Probabilities and binary states of hidden units.\n",
    "        \"\"\"\n",
    "        activation = np.dot(v, self.W) + self.c\n",
    "        p_h = self.sigmoid(activation)\n",
    "        h = (p_h > np.random.random(p_h.shape)).astype(float)\n",
    "        return p_h, h\n",
    "\n",
    "    def sample_visible(self, h):\n",
    "        \"\"\"\n",
    "        Sample visible units given hidden units.\n",
    "        Returns: Probabilities and binary states of visible units.\n",
    "        \"\"\"\n",
    "        activation = np.dot(h, self.W.T) + self.b\n",
    "        p_v = self.sigmoid(activation)\n",
    "        v = (p_v > np.random.random(p_v.shape)).astype(float)\n",
    "        return p_v, v\n",
    "\n",
    "    def contrastive_divergence(self, v):\n",
    "        \"\"\"\n",
    "        Perform one step of Contrastive Divergence (CD-k).\n",
    "        Returns: Positive and negative gradients for weights and biases.\n",
    "        \"\"\"\n",
    "        # Positive phase\n",
    "        pos_h_prob, pos_h = self.sample_hidden(v)\n",
    "        pos_assoc = np.dot(v.T, pos_h_prob)\n",
    "\n",
    "        # Negative phase (k steps of Gibbs sampling)\n",
    "        neg_v = v.copy()\n",
    "        for _ in range(self.k):\n",
    "            neg_h_prob, neg_h = self.sample_hidden(neg_v)\n",
    "            neg_v_prob, neg_v = self.sample_visible(neg_h)\n",
    "        \n",
    "        neg_assoc = np.dot(neg_v.T, neg_h_prob)\n",
    "\n",
    "        # Gradients\n",
    "        grad_W = pos_assoc - neg_assoc\n",
    "        grad_b = np.mean(v - neg_v, axis=0)\n",
    "        grad_c = np.mean(pos_h_prob - neg_h_prob, axis=0)\n",
    "\n",
    "        return grad_W, grad_b, grad_c\n",
    "\n",
    "    def train(self, data, epochs=100, batch_size=100):\n",
    "        \"\"\"\n",
    "        Train the RBM using Contrastive Divergence.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: Training data (binary, shape: [n_samples, n_visible])\n",
    "        - epochs: Number of training epochs\n",
    "        - batch_size: Size of mini-batches\n",
    "        \"\"\"\n",
    "        n_samples = data.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            error = 0\n",
    "            for start in range(0, n_samples, batch_size):\n",
    "                end = min(start + batch_size, n_samples)\n",
    "                batch = data[start:end]\n",
    "\n",
    "                # Compute gradients\n",
    "                grad_W, grad_b, grad_c = self.contrastive_divergence(batch)\n",
    "\n",
    "                # Update weights and biases\n",
    "                self.W += self.learning_rate * grad_W / batch_size\n",
    "                self.b += self.learning_rate * grad_b\n",
    "                self.c += self.learning_rate * grad_c\n",
    "\n",
    "                # Compute reconstruction error\n",
    "                error += np.mean((batch - self.sample_visible(self.sample_hidden(batch)[1])[1])**2)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch}, Reconstruction Error: {error / (n_samples // batch_size):.4f}\")\n",
    "\n",
    "    def reconstruct(self, v):\n",
    "        \"\"\"\n",
    "        Reconstruct input data by sampling hidden and then visible units.\n",
    "        Returns: Reconstructed visible units.\n",
    "        \"\"\"\n",
    "        _, h = self.sample_hidden(v)\n",
    "        _, v_reconstructed = self.sample_visible(h)\n",
    "        return v_reconstructed\n",
    "\n",
    "# Example usage with synthetic binary data\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate synthetic binary data (e.g., 100 samples with 10 visible units)\n",
    "    np.random.seed(42)\n",
    "    data = (np.random.random((100, 10)) > 0.5).astype(float)\n",
    "    \n",
    "    # Initialize and train RBM\n",
    "    rbm = RBM(n_visible=10, n_hidden=5, learning_rate=0.1, k=1)\n",
    "    rbm.train(data, epochs=100, batch_size=10)\n",
    "    \n",
    "    # Reconstruct a sample\n",
    "    sample = data[0:1]\n",
    "    reconstructed = rbm.reconstruct(sample)\n",
    "    print(\"Original:\", sample)\n",
    "    print(\"Reconstructed:\", reconstructed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
