{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJIOEDH9M9IOrzr8GxDQSp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajit-ai/DataScience/blob/main/Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Set Python executable for PySpark (important for Windows)\n",
        "os.environ[\"PYSPARK_PYTHON\"] = \"python\"\n",
        "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"python\"\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder.appName(\"PandasDemo\").getOrCreate()\n",
        "\n",
        "emp = [\n",
        "    (1, \"Smith\", -1, \"2018\", \"10\", \"M\", 3000),\n",
        "    (2, \"Rose\", 1, \"2010\", \"20\", \"M\", 4000),\n",
        "    (3, \"Williams\", 1, \"2010\", \"10\", \"M\", 1000),\n",
        "    (4, \"Jones\", 2, \"2005\", \"10\", \"F\", 2000),\n",
        "    (5, \"Brown\", 2, \"2010\", \"40\", \"\", -1),\n",
        "    (6, \"Brown\", 2, \"2010\", \"50\", \"\", -1)\n",
        "]\n",
        "empColumns = [\n",
        "    \"emp_id\", \"name\", \"superior_emp_id\", \"year_joined\",\n",
        "    \"emp_dept_id\", \"gender\", \"salary\"\n",
        "]\n",
        "\n",
        "empDF = spark.createDataFrame(data=emp, schema=empColumns)\n",
        "empDF.printSchema()\n",
        "empDF.show(truncate=False)\n",
        "\n",
        "dept = [\n",
        "    (\"Finance\", 10),\n",
        "    (\"Marketing\", 20),\n",
        "    (\"Sales\", 30),\n",
        "    (\"IT\", 40)\n",
        "]\n",
        "deptColumns = [\"dept_name\", \"dept_id\"]\n",
        "deptDF = spark.createDataFrame(data=dept, schema=deptColumns)\n",
        "deptDF.printSchema()\n",
        "deptDF.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBjdlkporlBj",
        "outputId": "91b0f56f-0299-4f3e-a67f-9e5547cceeb2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- emp_id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- superior_emp_id: long (nullable = true)\n",
            " |-- year_joined: string (nullable = true)\n",
            " |-- emp_dept_id: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "|1     |Smith   |-1             |2018       |10         |M     |3000  |\n",
            "|2     |Rose    |1              |2010       |20         |M     |4000  |\n",
            "|3     |Williams|1              |2010       |10         |M     |1000  |\n",
            "|4     |Jones   |2              |2005       |10         |F     |2000  |\n",
            "|5     |Brown   |2              |2010       |40         |      |-1    |\n",
            "|6     |Brown   |2              |2010       |50         |      |-1    |\n",
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "\n",
            "root\n",
            " |-- dept_name: string (nullable = true)\n",
            " |-- dept_id: long (nullable = true)\n",
            "\n",
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|Finance  |10     |\n",
            "|Marketing|20     |\n",
            "|Sales    |30     |\n",
            "|IT       |40     |\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark create RDD example\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df = spark.sparkContext.parallelize([(1, 2, 3, 'a b c'),\n",
        "             (4, 5, 6, 'd e f'),\n",
        "             (7, 8, 9, 'g h i')]).toDF(['col1', 'col2', 'col3','col4'])\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ckh-7dDe1kfp",
        "outputId": "b4baff45-609f-4508-f11c-911f711c5984"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----+-----+\n",
            "|col1|col2|col3| col4|\n",
            "+----+----+----+-----+\n",
            "|   1|   2|   3|a b c|\n",
            "|   4|   5|   6|d e f|\n",
            "|   7|   8|   9|g h i|\n",
            "+----+----+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "            .appName('SparkByExamples.com') \\\n",
        "            .getOrCreate()\n",
        "\n",
        "# Create RDD\n",
        "dept = [(\"Finance\",10),(\"Marketing\",20),(\"Sales\",30),(\"IT\",40)]\n",
        "rdd = spark.sparkContext.parallelize(dept)\n",
        "\n",
        "# Create DataFrame from RDD\n",
        "df = rdd.toDF()\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL-2ABMf1reB",
        "outputId": "e469bce5-ba14-4c81-d932-47b26cffcaef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _1: string (nullable = true)\n",
            " |-- _2: long (nullable = true)\n",
            "\n",
            "+---------+---+\n",
            "|_1       |_2 |\n",
            "+---------+---+\n",
            "|Finance  |10 |\n",
            "|Marketing|20 |\n",
            "|Sales    |30 |\n",
            "|IT       |40 |\n",
            "+---------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession \\\n",
        ".builder \\\n",
        ".appName(\"Python Spark create RDD example\") \\\n",
        ".config(\"spark.some.config.option\", \"some-value\") \\\n",
        ".getOrCreate()\n",
        "myData = spark.sparkContext.parallelize([(1,2), (3,4), (5,6), (7,8), (9,10)])\n",
        "myData.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYPxRmI21w9k",
        "outputId": "bb2d2a84-8354-4f4c-9857-dc82254d1dcb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 2), (3, 4), (5, 6), (7, 8), (9, 10)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession \\\n",
        ".builder \\\n",
        ".appName(\"Python Spark create RDD example\") \\\n",
        ".config(\"spark.some.config.option\", \"some-value\") \\\n",
        ".getOrCreate()\n",
        "Employee = spark.createDataFrame([\n",
        "('1', 'Joe', '70000', '1'),\n",
        "('2', 'Henry', '80000', '2'),\n",
        "('3', 'Sam', '60000', '2'),\n",
        "('4', 'Max', '90000', '1')],\n",
        "['Id', 'Name', 'Sallary','DepartmentId']\n",
        ")\n",
        "Employee.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ9VPAmT11cZ",
        "outputId": "4d99555e-4c3e-484e-826e-2633cfd8dd56"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+-------+------------+\n",
            "| Id| Name|Sallary|DepartmentId|\n",
            "+---+-----+-------+------------+\n",
            "|  1|  Joe|  70000|           1|\n",
            "|  2|Henry|  80000|           2|\n",
            "|  3|  Sam|  60000|           2|\n",
            "|  4|  Max|  90000|           1|\n",
            "+---+-----+-------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Set Python executable for PySpark (important for Windows)\n",
        "os.environ[\"PYSPARK_PYTHON\"] = \"python\"\n",
        "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"python\"\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder.appName(\"PandasDemo\").getOrCreate()\n",
        "\n",
        "emp = [\n",
        "    (1, \"Smith\", -1, \"2018\", \"10\", \"M\", 3000),\n",
        "    (2, \"Rose\", 1, \"2010\", \"20\", \"M\", 4000),\n",
        "    (3, \"Williams\", 1, \"2010\", \"10\", \"M\", 1000),\n",
        "    (4, \"Jones\", 2, \"2005\", \"10\", \"F\", 2000),\n",
        "    (5, \"Brown\", 2, \"2010\", \"40\", \"\", -1),\n",
        "    (6, \"Brown\", 2, \"2010\", \"50\", \"\", -1)\n",
        "]\n",
        "empColumns = [\n",
        "    \"emp_id\", \"name\", \"superior_emp_id\", \"year_joined\",\n",
        "    \"emp_dept_id\", \"gender\", \"salary\"\n",
        "]\n",
        "\n",
        "empDF = spark.createDataFrame(data=emp, schema=empColumns)\n",
        "empDF.printSchema()\n",
        "empDF.show(truncate=False)\n",
        "\n",
        "dept = [\n",
        "    (\"Finance\", 10),\n",
        "    (\"Marketing\", 20),\n",
        "    (\"Sales\", 30),\n",
        "    (\"IT\", 40)\n",
        "]\n",
        "deptColumns = [\"dept_name\", \"dept_id\"]\n",
        "deptDF = spark.createDataFrame(data=dept, schema=deptColumns)\n",
        "deptDF.printSchema()\n",
        "deptDF.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYkhPh9O3jQb",
        "outputId": "232e9758-d897-4cb5-b694-220a503cf456"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- emp_id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- superior_emp_id: long (nullable = true)\n",
            " |-- year_joined: string (nullable = true)\n",
            " |-- emp_dept_id: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "|1     |Smith   |-1             |2018       |10         |M     |3000  |\n",
            "|2     |Rose    |1              |2010       |20         |M     |4000  |\n",
            "|3     |Williams|1              |2010       |10         |M     |1000  |\n",
            "|4     |Jones   |2              |2005       |10         |F     |2000  |\n",
            "|5     |Brown   |2              |2010       |40         |      |-1    |\n",
            "|6     |Brown   |2              |2010       |50         |      |-1    |\n",
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "\n",
            "root\n",
            " |-- dept_name: string (nullable = true)\n",
            " |-- dept_id: long (nullable = true)\n",
            "\n",
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|Finance  |10     |\n",
            "|Marketing|20     |\n",
            "|Sales    |30     |\n",
            "|IT       |40     |\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}